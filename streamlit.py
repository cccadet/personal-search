import os
import streamlit as st
from crewai import Crew
from search.context.crew_chat import (
    library_agent, commentary_agent, library_search_task,
    literary_commentary_task, bible_agent, bible_search_task,
    revisor_agent, revisor_task,
    library_select_task, final_revisor_agent
)

# Configura√ß√µes locais
LOCAL_EMBEDDINGS_URL = "http://localhost:11434/api/embeddings"
EMBEDDINGS_MODEL = "nomic-embed-text:v1.5"
os.environ["LOCAL_EMBEDDINGS"] = LOCAL_EMBEDDINGS_URL
os.environ["LOCAL_EMBEDDINGS_MODEL"] = EMBEDDINGS_MODEL

# Configura√ß√µes da API OpenAI
os.environ["OPENAI_MODEL_NAME"] = 'gpt-3.5-turbo'

# Configura√ß√µes de DEBUG
os.environ["DEBUG"] = "False"
DEBUG_MODE = os.getenv("DEBUG_MODE", "False").lower() == "true"
VERBOSE = 2 if DEBUG_MODE else False

# T√≠tulo da aplica√ß√£o Streamlit
st.title("üí¨ Pesquisa Pessoal")

# Inicializa√ß√£o do estado da sess√£o para mensagens
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant",
                                     "content": "Qual assunto deseja pesquisar? Voc√™ tem acesso a sua biblioteca pessoal e a B√≠blia."}]

# Exibi√ß√£o das mensagens
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# Entrada do usu√°rio
if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # Configura√ß√£o e execu√ß√£o do Crew
    crew = Crew(
        agents=[library_agent, revisor_agent, commentary_agent, bible_agent, final_revisor_agent],
        tasks=[library_search_task, library_select_task, literary_commentary_task, bible_search_task, revisor_task],
        verbose=VERBOSE,
        memory=False,
    )
    inputs = {"text": prompt}
    final = crew.kickoff(inputs=inputs)

    # Exibi√ß√£o do resultado
    result = f"## Aqui est√° o resultado final \n\n {final}"
    st.session_state.messages.append({"role": "assistant", "content": result})
    st.chat_message("assistant").write(result)