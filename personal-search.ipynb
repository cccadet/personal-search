{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text:v1.5')\n",
    "\n",
    "path_books = os.path.join(os.path.dirname(__file__), \"vector-store\", \"books\")\n",
    "db = FAISS.load_local(path_books, embeddings, allow_dangerous_deserialization=True)\n",
    "print(db.index.ntotal)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs[\"distance_metric\"] = \"cos\"\n",
    "retriever.search_kwargs[\"fetch_k\"] = 100\n",
    "retriever.search_kwargs[\"maximal_marginal_relevance\"] = True\n",
    "retriever.search_kwargs[\"k\"] = 3\n",
    "\n",
    "template = '''\n",
    "    Você é um assistente de busca de livros.\n",
    "\n",
    "    Histórico de conversa: {chat_history}\n",
    "\n",
    "    Pergunta: {question}\n",
    "    '''\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"], template=template\n",
    ")\n",
    "\n",
    "llm = Ollama(model=\"mistral:7b\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
