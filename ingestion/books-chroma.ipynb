{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import books - PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "import logging\n",
    "\n",
    "# sset logging level to INFO\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder with the books to be imported\n",
    "path_books = './books/import'\n",
    "# Path to the folder with the books that have already been imported\n",
    "path_done_books = './books/done'\n",
    "# Path to the folder with vector store\n",
    "path_vector_store = '../vector-store/chroma/books'\n",
    "# Chunk size for the vector store\n",
    "# chunkSize controls the max size (in terms of number of characters) of the final documents. \n",
    "# chunkOverlap specifies how much overlap there should be between chunks. \n",
    "# This is often helpful to make sure that the text isn't split weirdly.\n",
    "chunk_size = 1000\n",
    "# Define embedding model\n",
    "embeddings = OllamaEmbeddings(model='nomic-embed-text:v1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_books(path_books):\n",
    "    \"\"\"\n",
    "    Load books from the specified path.\n",
    "\n",
    "    Args:\n",
    "        path_books (str): The path to the directory containing the books.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of file paths for the books found in the directory.\n",
    "    \"\"\"\n",
    "    logging.info(f'Loading books from {path_books}')\n",
    "    books = []\n",
    "    for root, dirs, files in os.walk(path_books):\n",
    "        for file in files:\n",
    "            if file.endswith('.pdf'):\n",
    "                books.append(os.path.join(root, file))\n",
    "    return books\n",
    "\n",
    "def load_pdf(file):\n",
    "    \"\"\"\n",
    "    Loads a PDF file and returns the extracted documents with PyPDFLoader.\n",
    "\n",
    "    Args:\n",
    "        file (str): The path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of extracted documents from the PDF.\n",
    "\n",
    "    \"\"\"\n",
    "    logging.info(f'Loading PDF {file}')\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def load_chunked_docs(documents):\n",
    "    \"\"\"\n",
    "    Chunk documents.\n",
    "\n",
    "    Args:\n",
    "        documents (list): A list of documents to be chunked.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of chunked documents.\n",
    "\n",
    "    \"\"\"\n",
    "    logging.info(f'Chunking documents')\n",
    "    text_spliter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    chunked_docs = text_spliter.split_documents(documents)\n",
    "    return chunked_docs\n",
    "\n",
    "def load_vector_store(chunked_docs, path_vector_store):\n",
    "    \"\"\"\n",
    "    Loads or creates a vector store using FAISS.\n",
    "\n",
    "    Args:\n",
    "        chunked_docs (list): A list of chunked documents.\n",
    "        path_vector_store (str): The path to the vector store.\n",
    "\n",
    "    Returns:\n",
    "        FAISS object: The loaded or created vector store.\n",
    "\n",
    "    Raises:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path_vector_store):\n",
    "        logging.info(f'Creating vector store')\n",
    "        os.makedirs(path_vector_store)\n",
    "        db = Chroma.from_documents(chunked_docs, embeddings, persist_directory=path_vector_store)\n",
    "        return db\n",
    "    else:\n",
    "        logging.info(f'Loading vector store')\n",
    "        db = Chroma(persist_directory=path_vector_store, embedding_function=embeddings)\n",
    "        logging.info(f'Adding documents to vector store')\n",
    "        db.add_documents(chunked_docs)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading books from ./books/import\n"
     ]
    }
   ],
   "source": [
    "# Load books from path\n",
    "books = load_books(path_books)\n",
    "# Process each book\n",
    "for book in books:\n",
    "    logging.info(f'Processing book {book}')\n",
    "    documents_books = load_pdf(book)\n",
    "    chunked_docs = load_chunked_docs(documents_books)\n",
    "    db = load_vector_store(chunked_docs=chunked_docs, path_vector_store=path_vector_store)\n",
    "    logging.info(f'Moving book {book} to {path_done_books}')\n",
    "    os.rename(book, os.path.join(path_done_books, os.path.basename(book)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VectorStoreRetriever' object has no attribute 'similarity_search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m db \u001b[38;5;241m=\u001b[39m Chroma(persist_directory\u001b[38;5;241m=\u001b[39mpath_vector_store, embedding_function\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[1;32m      4\u001b[0m retriever \u001b[38;5;241m=\u001b[39m db\u001b[38;5;241m.\u001b[39mas_retriever(\n\u001b[1;32m      5\u001b[0m     search_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     search_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetch_k\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50\u001b[39m}\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalvinismo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'VectorStoreRetriever' object has no attribute 'similarity_search'"
     ]
    }
   ],
   "source": [
    "#testar se o documento foi adicionado\n",
    "#db = FAISS.load_local(\"../vector-store/books\", embeddings, allow_dangerous_deserialization=True)\n",
    "db = Chroma(persist_directory=path_vector_store, embedding_function=embeddings)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 5, 'fetch_k': 50}\n",
    ")\n",
    "\n",
    "results = retriever.get_relevant_documents(\"Calvinismo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page Content: \n",
      "5\n",
      " John Calvin, \n",
      "Commentaries on the Epistle of Paul to the Romans\n",
      ", trans. and ed. John Owen (repr., Grand Rapids: Baker, 2003),\n",
      "354.\n",
      "\n",
      "Source: \n",
      "./books/import/Somos Todos Teólogos - RC Sproul.pdf \n",
      "\n",
      "Page:\n",
      "94\n",
      "\n",
      "\n",
      "\n",
      "Page Content: \n",
      "6\n",
      " Bunyan aqui se refere à criada diante de quem Pedro negou a Cristo;\n",
      "conforme Mateus 26:69-72 e Lucas 22:56-57.\n",
      "\n",
      "Source: \n",
      "./books/import/O Peregrino - John Bunyan.pdf \n",
      "\n",
      "Page:\n",
      "196\n",
      "\n",
      "\n",
      "\n",
      "Page Content: \n",
      "Sumário\n",
      "1  A violência neuronal\n",
      "2  Além da sociedade disciplinar\n",
      "3  O tédio profundo\n",
      "4  Vita activa\n",
      "5  Pedagogia do ver\n",
      "6  O Caso Bartleby\n",
      "7  Sociedade do cansaço\n",
      "Textos de capa\n",
      "\n",
      "Source: \n",
      "./books/import/Sociedade do Cansaço - Byung-Chul Han.pdf \n",
      "\n",
      "Page:\n",
      "8\n",
      "\n",
      "\n",
      "\n",
      "Page Content: \n",
      "batalha confiando em nossa força, não devemos nos surpreender se voltarmos manchados pela\n",
      "derrota. Se não fosse pelo teu poder, ó Espírito de Deus, não poderíamos nem tentar; mas,\n",
      "quando confiamos em ti, seguimos adiante com fé.\n",
      "Ultimamente tenho sido tocado, ao olhar a história da Reforma e das épocas anteriores ela, pela\n",
      "franqueza do testemunho dos pregadores antigos. Se observarmos a vida de Farel, veremos que\n",
      "ele não pregava sobre o evangelho, mas o evangelho. João Calvino fazia o mesmo. Hoje, é claro,\n",
      "ele  é  visto  apenas  como  um  teólogo,  mas  na  verdade  foi  um  dos  maiores  pregadores  do\n",
      "evangelho. Quando João Calvino abria o Livro e escolhia um texto, podem ter certeza de que ele\n",
      "pregava: “Porque pela graça sois salvos, por meio da fé, e isto não vem de vós, é dom de Deus”\n",
      "(Ef 2.8). O mesmo acontecia com Lutero. A pregação de Lutero era como um grande sino,\n",
      "soando sempre a mesma nota: “Crê no Senhor Jesus Cristo e viverás! Não somos salvos por\n",
      "\n",
      "Source: \n",
      "./books/import/Conselhos para obreiros - Charles H Spurgeon.pdf \n",
      "\n",
      "Page:\n",
      "20\n",
      "\n",
      "\n",
      "\n",
      "Page Content: \n",
      "numa absolutização unilateral da potência positiva.\n",
      "[25]. NIETZSCHE, F . Menschliches, Allz umenschliches I . Op. cit., p. 235s.\n",
      "\n",
      "Source: \n",
      "./books/import/Sociedade do Cansaço - Byung-Chul Han.pdf \n",
      "\n",
      "Page:\n",
      "36\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in results:\n",
    "    page_content = row.page_content\n",
    "    source = row.metadata['source']\n",
    "    page = row.metadata['page']\n",
    "\n",
    "    \n",
    "\n",
    "    # Agora você pode fazer o que quiser com esses dados.\n",
    "    # Por exemplo, você pode imprimi-los:\n",
    "    print(f\"\"\"\n",
    "Page Content: \n",
    "{page_content.replace('\t',' ')}\n",
    "\n",
    "Source: \n",
    "{source} \n",
    "\n",
    "Page:\n",
    "{page}\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
